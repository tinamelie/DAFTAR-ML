"""File handling utilities for managing outputs and documentation."""

import os
from pathlib import Path
from typing import Optional, Dict, Any, List


def create_figures_explanation(output_dir: Path) -> None:
    """Generate a comprehensive explanation file for DAFTAR-ML outputs.

    Args:
        output_dir: Path to the directory where the explanation file will be saved.
    """
    explanation_text = [
        "DAFTAR-ML OUTPUT FILES EXPLANATION",
        "=" * 80,
        "",
        "This document explains files and visualizations generated by DAFTAR-ML.",
        "",
        "1. OUTPUT STRUCTURE",
        "-" * 80,
        "- Main directory: Contains overall metrics, SHAP visualizations, and summary files.",
        "- feature_importance directory: Contains feature importance data and visualizations.",
        "- fold_X directories: Contain results specific to each cross-validation fold.",
        "- fold_X/optuna_plots directories: Visualizations related to hyperparameter optimization within each fold directory.",
        "",
        "2. SAMPLE-LEVEL VS. FOLD-LEVEL CALCULATIONS",
        "-" * 80,
        "Sample-level (_sample): Calculated from all individual samples. Reflects overall impact but sensitive to outliers.",
        "Fold-level (_fold): Averaged within folds first, then across folds. Reflects consistent impact across data splits.",
        "",
        "3. SHAP ANALYSIS VISUALIZATIONS",
        "-" * 80,
        "Beeswarm Plots:",
        "- shap_beeswarm_sample.png (Sample-level): Distribution of individual sample impacts.",
        "  Uses Sample_Level_Impact for feature ranking and Sample_Impact_Direction for coloring.",
        "- shap_beeswarm_fold.png (Fold-level): Distribution of fold-averaged impacts.",
        "  Uses Fold_Level_Impact for feature ranking and Fold_Impact_Direction for coloring.",
        "- Points right of center indicate positive impact, left indicate negative.",
        "",
        "Note: Beeswarm and bar plot rankings differ because beeswarm plots rank features by absolute magnitude, while bar plots separate features by direction (positive vs. negative impacts).",
        "",
        "Bar Plots:",
        "- shap_bar_sample.png: Top sample-level features by average SHAP value.",
        "  Uses Sample_Mean_SHAP for bar length and Sample_Impact_Direction for coloring.",
        "- shap_bar_fold.png: Top fold-level features with cross-validation error bars.",
        "  Uses Fold_Mean_SHAP for bar length, Fold_SHAP_StdDev for error bars, and Fold_Impact_Direction for coloring.",
        "- Red bars indicate positive impact, blue indicate negative.",
        "",
        "Correlation Plots (Regression Only):",
        "- shap_corr_bar_sample.png: Correlation of SHAP values and target at sample level.",
        "  Uses Sample_Level_Correlation for bar length and direction for coloring.",
        "- shap_corr_bar_fold.png: Correlation between SHAP values and target values at fold-level.",
        "  Uses Fold_Level_Correlation for bar length and direction for coloring.",
        "",
        "4. FEATURE IMPORTANCE VISUALIZATIONS",
        "-" * 80,
        "Bar Plots:",
        "- feature_importance_bar_sample.png: Sample-level feature importance.",
        "- feature_importance_bar_fold.png: Fold-level feature importance with error bars.",
        "- Importance shown by magnitude; no directionality indicated.",
        "- Note: SHAP values provide a more nuanced interpretation compared to traditional feature importance, as they indicate both the magnitude and direction of feature effects.",
        "",
        "5. PREDICTION VISUALIZATIONS",
        "-" * 80,
        "Classification:",
        "- confusion_matrix_global.png: Overall confusion matrix.",
        "- fold_X/confusion_matrix_fold_X.png: Fold-specific confusion matrices.",
        "",
        "Regression:",
        "- density_actual_vs_pred_global.png: Actual vs predicted value density plot.",
        "- fold_X/density_plot_fold_X.png: Fold-specific density plots.",
        "",
        "6. HYPERPARAMETER OPTIMIZATION VISUALIZATIONS",
        "-" * 80,
        "Located in fold_X/optuna_plots directories:",
        "- optuna_history_foldX.html: Objective value improvement over trials.",
        "- optuna_parallel_foldX.html: Relationship between hyperparameters and performance.",
        "- optuna_slice_foldX.html: Effect of individual hyperparameters.",
        "- fold_X/hyperparameter_tuning_summary_foldX.txt: Text summary.",
        "",
        "7. DATA FILES",
        "-" * 80,
        "SHAP Analysis Files:",
        "- shap_features_analysis.csv: Complete feature metrics with all the statistics used in plots.",
        "- shap_values_all_folds.csv: Combined SHAP values from all folds.",
        "- shap_values_fold_X.csv: Fold-specific SHAP values.",
        "",
        "Feature Importance Files:",
        "- feature_importance_values_sample.csv: Sample-level feature importance data.",
        "- feature_importance_values_fold.csv: Fold-level feature importance data.",
        "",
        "Prediction Files:",
        "- predictions_vs_actual_overall.csv: Combined predictions with actual values.",
        "- fold_X/predictions_vs_actual_fold_X.csv: Fold-specific predictions.",
        "",
        "Model and Metrics Files:",
        "- best_model_fold_X.pkl: Trained fold-specific models.",
        "- performance.txt: Summary metrics across folds.",
        "- DAFTAR-ML_run.log: Comprehensive analysis logs.",
        "Fold_Impact_Direction: Direction of impact (Positive or Negative)\n",
        "Sample_Mean_SHAP: Average SHAP value across all samples\n",
    ]

    with open(output_dir / "figures_explanation.txt", "w") as f:
        f.write("\n".join(explanation_text))



def save_shap_values(fold_results: List[Dict[str, Any]], output_dir: Path) -> None:
    """Save SHAP values from all folds to CSV files.
    
    Args:
        fold_results: List of fold results
        output_dir: Output directory path
    """
    import numpy as np
    import pandas as pd
    
    # Concatenate SHAP values from all folds
    all_samples_shap_values = []
    
    for fold_idx, fold_result in enumerate(fold_results):
        shap_values = fold_result['shap_values']
        X_test = fold_result['X_test']
        y_test = fold_result['y_test']
        feature_names = fold_result['feature_importances'].index.tolist()
        
        # Use original IDs if available, otherwise use test IDs
        if 'original_ids' in fold_result and fold_result['original_ids'] is not None:
            sample_ids = fold_result['original_ids']
        else:
            sample_ids = fold_result['ids_test']
        
        # Skip if no SHAP values (shouldn't happen)
        if shap_values is None or len(shap_values) == 0:
            continue
            
        # Handle different SHAP value shapes based on problem type
        # Classification models can have multiple formats based on the SHAP explainer
        if len(shap_values.shape) == 3:  # shape: (n_classes, n_samples, n_features)
            # For multiclass, we'll just use the values for class 1 (positive class)
            shap_values = shap_values[1]  # Select positive class SHAP values
        
        # Make sure we don't exceed the bounds of arrays
        n_samples = min(len(shap_values), len(sample_ids), len(y_test))
        
        # For each sample, collect all feature SHAP values
        for i in range(n_samples):
            sample_id = sample_ids[i]
            target_value = y_test[i]
            sample_shap = shap_values[i]
            
            # Handle feature dimension safely
            n_features = min(len(sample_shap), len(feature_names))
            
            # Store all SHAP values for this sample
            sample_shap_dict = {feature_names[j]: sample_shap[j] for j in range(n_features)}
            
            # Add metadata
            sample_shap_dict['ID'] = sample_id  # Use a consistent ID column name
            sample_shap_dict['Fold'] = fold_idx + 1  # 1-indexed folds
            sample_shap_dict['Target'] = target_value  # Add target value
            
            # Append to the list of samples
            all_samples_shap_values.append(sample_shap_dict)
    
    # Create DataFrame with one row per sample, features as columns
    shap_df = pd.DataFrame(all_samples_shap_values)
    
    # Collect all possible feature names from all folds
    all_feature_names = set()
    for fold_result in fold_results:
        if 'shap_data' in fold_result and fold_result['shap_data'] is not None:
            # Get feature names from X_test in shap_data
            fold_X_test = fold_result['shap_data'][1]
            if fold_X_test is not None and hasattr(fold_X_test, 'columns'):
                all_feature_names.update(fold_X_test.columns)
    
    # Ensure all features are present in the dataframe - avoid fragmentation
    missing_features = list(all_feature_names - set(shap_df.columns))
    if missing_features:
        # Create a DataFrame with zeros for missing features
        missing_df = pd.DataFrame(0.0, index=shap_df.index, columns=missing_features)
        # Concat with original DataFrame to avoid fragmentation
        shap_df = pd.concat([shap_df, missing_df], axis=1)
    
    # Reorder columns to put ID, Fold, and Target first
    metadata_cols = ['ID', 'Fold', 'Target']
    other_cols = sorted([col for col in shap_df.columns if col not in metadata_cols])
    ordered_cols = metadata_cols + other_cols
    shap_df = shap_df[ordered_cols]
    
    # Save to CSV
    shap_df.to_csv(output_dir / 'shap_values_all_folds.csv', index=False)
    
    # Save per-fold SHAP values
    for fold_idx, fold_result in enumerate(fold_results):
        fold_dir = output_dir / f"fold_{fold_idx+1}"
        fold_dir.mkdir(exist_ok=True)
        
        # Filter for this fold
        fold_shap_df = shap_df[shap_df['Fold'] == fold_idx + 1].copy()
        # Use the same column ordering as the main SHAP CSV
        fold_shap_df.to_csv(fold_dir / f"shap_values_fold_{fold_idx+1}.csv", index=False)
