"""File handling utilities for managing outputs and documentation."""

import os
from pathlib import Path
from typing import Optional, Dict, Any, List


def create_figures_explanation(output_dir: Path) -> None:
    """Generate a comprehensive explanation file for DAFTAR-ML outputs.

    Args:
        output_dir: Path to the directory where the explanation file will be saved.
    """
    explanation_text = [
        "DAFTAR-ML OUTPUT FILES EXPLANATION",
        "=" * 80,
        "",
        "This document explains files and visualizations generated by DAFTAR-ML.",
        "",
        "1. OUTPUT STRUCTURE",
        "-" * 80,
        "- Main directory: Contains overall metrics, SHAP visualizations, and summary files.",
        "- feature_importance directory: Contains feature importance data and visualizations.",
        "- fold_X directories: Contain results specific to each cross-validation fold.",
        "- fold_X/optuna_plots directories: Visualizations related to hyperparameter optimization within each fold directory.",
        "- shap_feature_interactions directory: Feature interaction analysis (XGBoost regression only).",
        "- per_class_shap directory: Class-specific feature importance analysis (Classification only).",
        "",
        "2. FOLD-LEVEL VS GLOBAL CALCULATIONS",
        "-" * 80,
        "All DAFTAR-ML metrics and visualizations are calculated using one of two approaches:",
        "- Fold-level: First averaged within each fold, then across folds. More robust to outliers and fold variations.",
        "- Global: Calculated across all samples. Captures overall feature impact patterns.",
        "",
        "3. SHAP ANALYSIS VISUALIZATIONS",
        "-" * 80,
        "A. Beeswarm Plots:",
        "- shap_beeswarm_impact.png: Distribution of SHAP values across all features.",
        "  Features are ranked by Fold_Level_Impact and colored by direction of impact.",
        "  Points right of center (red) increase predictions, left (blue) decrease predictions.",
        "",
        "B. Bar Plots:",
        "- shap_bar_impact.png: Features ranked by absolute SHAP impact regardless of direction.",
        "  Shows error bars representing cross-validation variation.",
        "  Red/blue indicate direction of impact (increases/decreases prediction).",
        "",
        "- shap_bar_pos_neg_impact.png: Top positive and negative impact features in one view.",
        "  Highlights the features that most strongly push predictions higher or lower.",
        "",
        "C. Correlation Plots (Regression Only):",
        "- shap_corr_bar_fold.png: Correlation between SHAP values and target values.",
        "  Red bars show positive correlation (higher feature → higher target)",
        "  Blue bars show negative correlation (higher feature → lower target)",
        "",
        "4. MODEL-SPECIFIC VISUALIZATIONS",
        "-" * 80,
        "A. XGBoost Regression Only:",
        "- shap_feature_interactions/interaction_network.png: Network graph showing feature interactions.",
        "- shap_feature_interactions/interaction_heatmap.png: Heatmap of interaction strengths.",
        "- shap_feature_interactions/interaction_matrix.csv: Full matrix of interaction values.",
        "- shap_feature_interactions/interaction_strength.csv: Ranked list of strongest interactions.",
        "",
        "B. Classification Only (XGBoost and Random Forest):",
        "- per_class_shap/all_classes_shap_stats.csv: Features important for each class.",
        "- per_class_shap/class_X_shap_impact.png: Impact plots for each individual class.",
        "- per_class_shap/multiclass_comparison.png: Comparison of features across classes (if >1 class).",
        "- confusion_matrix_global.png: Overall confusion matrix.",
        "- fold_X/confusion_matrix_fold_X.png: Fold-specific confusion matrices.",
        "",
        "C. Regression Only (XGBoost and Random Forest):",
        "- density_actual_vs_pred_global.png: Actual vs predicted value density plot.",
        "- fold_X/density_plot_fold_X.png: Fold-specific density plots.",
        "",
        "5. FEATURE IMPORTANCE VISUALIZATIONS",
        "-" * 80,
        "- feature_importance/feature_importance_values.csv: Overall feature importance statistics.",
        "- feature_importance/feature_importance_bar.png: Bar visualization of top features.",
        "- These are traditional feature importance measures (not SHAP), based on model-specific metrics.",
        "- Unlike SHAP, these only show magnitude (no directionality information).",
        "",
        "6. HYPERPARAMETER OPTIMIZATION VISUALIZATIONS",
        "-" * 80,
        "Located in fold_X/optuna_plots directories:",
        "- optuna_history_foldX.html: Objective value improvement over trials.",
        "- optuna_parallel_foldX.html: Relationship between hyperparameters and performance.",
        "- fold_X/hyperparameter_tuning_summary_foldX.txt: Text summary of tuning process.",
        "",
        "7. KEY DATA FILES",
        "-" * 80,
        "A. SHAP Analysis Files:",
        "- shap_features_analysis.csv: Complete feature metrics including:",
        "  * Fold_Mean_SHAP: Average directional SHAP value across folds",
        "  * Fold_SHAP_StdDev: Standard deviation of SHAP values across folds",
        "  * Fold_Level_Impact: Absolute magnitude of fold-level SHAP values",
        "  * Fold_Impact_Direction: Direction of impact (positive/negative)",
        "  * Fold_Level_Correlation: Correlation with target (regression only)",
        "- shap_features_summary.txt: Comprehensive feature analysis and rankings",
        "- shap_values_all_folds.csv: Combined SHAP values from all folds",
        "",
        "B. Prediction Files:",
        "- predictions_vs_actual_overall.csv: Combined predictions with actual values",
        "- fold_X/predictions_vs_actual_fold_X.csv: Fold-specific predictions",
        "",
        "C. Model and Metrics Files:",
        "- best_model_fold_X.pkl: Trained fold-specific models",
        "- performance.txt: Summary metrics across folds",
        "- DAFTAR-ML_run.log: Comprehensive analysis logs",
        "- config.json: Record of all settings used in the analysis",
        "- figures_explanation.txt: This file explaining all outputs",
    ]

    with open(output_dir / "figures_explanation.txt", "w") as f:
        f.write("\n".join(explanation_text))



def save_shap_values(fold_results: List[Dict[str, Any]], output_dir: Path) -> None:
    """Save SHAP values from all folds to CSV files.
    
    Args:
        fold_results: List of fold results
        output_dir: Output directory path
    """
    import numpy as np
    import pandas as pd
    
    # Concatenate SHAP values from all folds
    all_samples_shap_values = []
    
    for fold_idx, fold_result in enumerate(fold_results):
        shap_values = fold_result['shap_values']
        X_test = fold_result['X_test']
        y_test = fold_result['y_test']
        feature_names = fold_result['feature_importances'].index.tolist()
        
        # Use original IDs if available, otherwise use test IDs
        if 'original_ids' in fold_result and fold_result['original_ids'] is not None:
            sample_ids = fold_result['original_ids']
        else:
            sample_ids = fold_result['ids_test']
        
        # Skip if no SHAP values (shouldn't happen)
        if shap_values is None or len(shap_values) == 0:
            continue
            
        # Handle different SHAP value shapes based on problem type
        # Classification models can have multiple formats based on the SHAP explainer
        if len(shap_values.shape) == 3:  # shape: (n_classes, n_samples, n_features)
            # For multiclass, we'll just use the values for class 1 (positive class)
            shap_values = shap_values[1]  # Select positive class SHAP values
        
        # Make sure we don't exceed the bounds of arrays
        n_samples = min(len(shap_values), len(sample_ids), len(y_test))
        
        # For each sample, collect all feature SHAP values
        for i in range(n_samples):
            sample_id = sample_ids[i]
            target_value = y_test[i]
            sample_shap = shap_values[i]
            
            # Handle feature dimension safely
            n_features = min(len(sample_shap), len(feature_names))
            
            # Store all SHAP values for this sample
            sample_shap_dict = {feature_names[j]: sample_shap[j] for j in range(n_features)}
            
            # Add metadata
            sample_shap_dict['ID'] = sample_id  # Use a consistent ID column name
            sample_shap_dict['Fold'] = fold_idx + 1  # 1-indexed folds
            sample_shap_dict['Target'] = target_value  # Add target value
            
            # Append to the list of samples
            all_samples_shap_values.append(sample_shap_dict)
    
    # Create DataFrame with one row per sample, features as columns
    shap_df = pd.DataFrame(all_samples_shap_values)
    
    # Collect all possible feature names from all folds
    all_feature_names = set()
    for fold_result in fold_results:
        if 'shap_data' in fold_result and fold_result['shap_data'] is not None:
            # Get feature names from X_test in shap_data
            fold_X_test = fold_result['shap_data'][1]
            if fold_X_test is not None and hasattr(fold_X_test, 'columns'):
                all_feature_names.update(fold_X_test.columns)
    
    # Ensure all features are present in the dataframe - avoid fragmentation
    missing_features = list(all_feature_names - set(shap_df.columns))
    if missing_features:
        # Create a DataFrame with zeros for missing features
        missing_df = pd.DataFrame(0.0, index=shap_df.index, columns=missing_features)
        # Concat with original DataFrame to avoid fragmentation
        shap_df = pd.concat([shap_df, missing_df], axis=1)
    
    # Reorder columns to put ID, Fold, and Target first
    metadata_cols = ['ID', 'Fold', 'Target']
    other_cols = sorted([col for col in shap_df.columns if col not in metadata_cols])
    ordered_cols = metadata_cols + other_cols
    shap_df = shap_df[ordered_cols]
    
    # Save to CSV
    shap_df.to_csv(output_dir / 'shap_values_all_folds.csv', index=False)
    
    # Save per-fold SHAP values
    for fold_idx, fold_result in enumerate(fold_results):
        fold_dir = output_dir / f"fold_{fold_idx+1}"
        fold_dir.mkdir(exist_ok=True)
        
        # Filter for this fold
        fold_shap_df = shap_df[shap_df['Fold'] == fold_idx + 1].copy()
        # Use the same column ordering as the main SHAP CSV
        fold_shap_df.to_csv(fold_dir / f"shap_values_fold_{fold_idx+1}.csv", index=False)
