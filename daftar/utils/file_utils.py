"""File handling utilities for managing outputs and documentation."""

import os
from pathlib import Path
from typing import Optional, Dict, Any, List


def create_figures_explanation(output_dir: Path) -> None:
    """Create explanation file for all figures.
    
    Args:
        output_dir: Output directory path
    """
    explanation_text = [
        "DAFTAR-ML OUTPUT FILES EXPLANATION",
        "=" * 80,
        "",
        "This document explains the various files and visualizations generated by DAFTAR-ML.",
        "",
        "1. OVERVIEW OF OUTPUT ORGANIZATION",
        "-" * 80,
        "DAFTAR-ML organizes results in a structured way:",
        "- Main output directory: Contains global visualizations and summary files",
        "- fold_X/ directories: Contain fold-specific results",
        "- feature_importance/ directory: Contains feature importance visualizations and data files",
        "- optuna_plots/ directories: Contain hyperparameter optimization visualizations",
        "",
        "2. SAMPLE-LEVEL VS. FOLD-LEVEL CALCULATIONS",
        "-" * 80,
        "DAFTAR-ML uses two complementary methods for analyzing feature importance:",
        "",
        "Sample-level (all samples combined):",
        "- Calculated using all individual samples across all folds",
        "- Shows overall feature impact across the full dataset",
        "- May be more influenced by outliers",
        "- Identified by '_sample' suffix in filenames",
        "",
        "Fold-level (fold averages combined):",
        "- First calculates averages within each fold, then averages across folds",
        "- Shows features that are consistently important across different data splits",
        "- More robust to random variation",
        "- Identified by '_fold' suffix in filenames",
        "",
        "3. SHAP ANALYSIS VISUALIZATIONS",
        "-" * 80,
        "",
        "SHAP Beeswarm Plots:",
        "- shap_beeswarm_sample.png: Sample-level SHAP values distribution",
        "- shap_beeswarm_fold.png: Fold-level SHAP values distribution",
        "Each dot represents a sample or fold average, with color indicating the feature value (red=high, blue=low).",
        "Features are ordered by their SHAP impact. Points to the right have positive impact, left have negative impact.",
        "",
        "SHAP Bar Plots:",
        "- shap_bar_sample.png: Top features by sample-level impact",
        "- shap_bar_fold.png: Top features by fold-level impact (includes cross-validation error bars)",
        "These plots show the average SHAP value impact for the most important features.",
        "Positive values (red) increase predictions, negative values (blue) decrease predictions.",
        "",
        "SHAP Correlation Plots (Regression Only):",
        "- shap_corr_bar_sample.png: Correlation between SHAP values and target at sample level",
        "- shap_corr_bar_fold.png: Correlation between SHAP values and target at fold level",
        "- shap_corr_sample.csv: Raw correlation data at sample level",
        "- shap_corr_fold.csv: Raw correlation data at fold level",
        "These plots show how consistently feature SHAP values align with the target variable.",
        "Positive correlation (red) means the feature's SHAP values tend to match the target's direction.",
        "Negative correlation (blue) means the feature's SHAP values tend to oppose the target's direction.",
        "",
        "4. FEATURE IMPORTANCE VISUALIZATIONS",
        "-" * 80,
        "",
        "Feature Importance Bar Plots:",
        "- feature_importance/feature_importance_bar_sample.png: Sample-level importance",
        "- feature_importance/feature_importance_bar_fold.png: Fold-level importance",
        "These plots show traditional feature importance values from the model with error bars.",
        "Unlike SHAP values, these don't indicate direction (positive/negative), only magnitude of importance.",
        "Error bars show standard deviation of importance across folds.",
        "",
        "5. PREDICTION VISUALIZATIONS",
        "-" * 80,
        "",
        "For Classification:",
        "- confusion_matrix_global.png: Overall confusion matrix for all folds combined",
        "- fold_X/confusion_matrix_fold_X.png: Confusion matrix for specific fold",
        "",
        "For Regression:",
        "- density_actual_vs_pred_global.png: Distribution of actual vs. predicted values (all folds)",
        "- fold_X/density_plot_fold_X.png: Density plot for specific fold",
        "Includes performance metrics in the right margin.",
        "",
        "6. HYPERPARAMETER OPTIMIZATION VISUALIZATIONS",
        "-" * 80,
        "",
        "Located in fold_X/optuna_plots/ directories:",
        "- optuna_history_foldX.html: Shows how the objective value improved over trials",
        "- optuna_parallel_foldX.html: Shows relationship between hyperparameters and performance",
        "- optuna_slice_foldX.html: Shows effect of each hyperparameter on performance",
        "- fold_X/hyperparameter_tuning_summary_foldX.txt: Text summary of hyperparameter optimization",
        "",
        "7. DATA FILES",
        "-" * 80,
        "",
        "SHAP Analysis Files:",
        "- shap_values_all_folds.csv: Combined SHAP values from all folds with metadata",
        "- fold_X/shap_values_fold_X.csv: SHAP values for specific fold",
        "- shap_feature_metrics.csv: Statistical summary of SHAP values with sample/fold metrics",
        "- shap_features_summary.txt: Comprehensive analysis of feature impacts and rankings",
        "",
        "Feature Importance Files:",
        "- feature_importance/feature_importance_values_sample.csv: Sample-level feature importance",
        "- feature_importance/feature_importance_values_fold.csv: Fold-level feature importance",
        "- fold_X/feature_importance_fold_X.csv: Feature importance for specific fold",
        "",
        "Prediction Files:",
        "- predictions_vs_actual_overall.csv: All predictions with true values",
        "  * For classification: Includes 'Correct' column (True/False)", 
        "  * For regression: Includes Residual and Abs_Residual columns",
        "- fold_X/predictions_vs_actual_fold_X.csv: Predictions for specific fold",
        "",
        "Model and Metrics:", 
        "- fold_X/best_model_fold_X.pkl: Trained model for specific fold",
        "- performance.txt: Performance metrics averaged across all folds",
        "- DAFTAR-ML_*.log: Complete log files of analysis runs",
    ]
    
    with open(output_dir / "figures_explanation.txt", "w") as f:
        f.write("\n".join(explanation_text))


def save_shap_values(fold_results: List[Dict[str, Any]], output_dir: Path) -> None:
    """Save SHAP values from all folds to CSV files.
    
    Args:
        fold_results: List of fold results
        output_dir: Output directory path
    """
    import numpy as np
    import pandas as pd
    
    # Concatenate SHAP values from all folds
    all_samples_shap_values = []
    
    for fold_idx, fold_result in enumerate(fold_results):
        shap_values = fold_result['shap_values']
        X_test = fold_result['X_test']
        y_test = fold_result['y_test']
        feature_names = fold_result['feature_importances'].index.tolist()
        
        # Use original IDs if available, otherwise use test IDs
        if 'original_ids' in fold_result and fold_result['original_ids'] is not None:
            sample_ids = fold_result['original_ids']
        else:
            sample_ids = fold_result['ids_test']
        
        # Skip if no SHAP values (shouldn't happen)
        if shap_values is None or len(shap_values) == 0:
            continue
            
        # Handle different SHAP value shapes based on problem type
        # Classification models can have multiple formats based on the SHAP explainer
        if len(shap_values.shape) == 3:  # shape: (n_classes, n_samples, n_features)
            # For multiclass, we'll just use the values for class 1 (positive class)
            shap_values = shap_values[1]  # Select positive class SHAP values
        
        # Make sure we don't exceed the bounds of arrays
        n_samples = min(len(shap_values), len(sample_ids), len(y_test))
        
        # For each sample, collect all feature SHAP values
        for i in range(n_samples):
            sample_id = sample_ids[i]
            target_value = y_test[i]
            sample_shap = shap_values[i]
            
            # Handle feature dimension safely
            n_features = min(len(sample_shap), len(feature_names))
            
            # Store all SHAP values for this sample
            sample_shap_dict = {feature_names[j]: sample_shap[j] for j in range(n_features)}
            
            # Add metadata
            sample_shap_dict['ID'] = sample_id  # Use a consistent ID column name
            sample_shap_dict['Fold'] = fold_idx + 1  # 1-indexed folds
            sample_shap_dict['Target'] = target_value  # Add target value
            
            # Append to the list of samples
            all_samples_shap_values.append(sample_shap_dict)
    
    # Create DataFrame with one row per sample, features as columns
    shap_df = pd.DataFrame(all_samples_shap_values)
    
    # Collect all possible feature names from all folds
    all_feature_names = set()
    for fold_result in fold_results:
        if 'shap_data' in fold_result and fold_result['shap_data'] is not None:
            # Get feature names from X_test in shap_data
            fold_X_test = fold_result['shap_data'][1]
            if fold_X_test is not None and hasattr(fold_X_test, 'columns'):
                all_feature_names.update(fold_X_test.columns)
    
    # Ensure all features are present in the dataframe - avoid fragmentation
    missing_features = list(all_feature_names - set(shap_df.columns))
    if missing_features:
        # Create a DataFrame with zeros for missing features
        missing_df = pd.DataFrame(0.0, index=shap_df.index, columns=missing_features)
        # Concat with original DataFrame to avoid fragmentation
        shap_df = pd.concat([shap_df, missing_df], axis=1)
    
    # Reorder columns to put ID, Fold, and Target first
    metadata_cols = ['ID', 'Fold', 'Target']
    other_cols = sorted([col for col in shap_df.columns if col not in metadata_cols])
    ordered_cols = metadata_cols + other_cols
    shap_df = shap_df[ordered_cols]
    
    # Save to CSV
    shap_df.to_csv(output_dir / 'shap_values_all_folds.csv', index=False)
    
    # Save per-fold SHAP values
    for fold_idx, fold_result in enumerate(fold_results):
        fold_dir = output_dir / f"fold_{fold_idx+1}"
        fold_dir.mkdir(exist_ok=True)
        
        # Filter for this fold
        fold_shap_df = shap_df[shap_df['Fold'] == fold_idx + 1].copy()
        # Use the same column ordering as the main SHAP CSV
        fold_shap_df.to_csv(fold_dir / f"shap_values_fold_{fold_idx+1}.csv", index=False)
